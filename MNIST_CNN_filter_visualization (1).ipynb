{"cells": [{"metadata": {"colab": {}, "colab_type": "code", "id": "NCf2oMCBI4k9"}, "cell_type": "code", "source": "from __future__ import print_function\n#%tensorflow_version 1.x\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport math\nimport os\nimport errno\nimport shutil", "execution_count": 3, "outputs": [{"output_type": "error", "ename": "ModuleNotFoundError", "evalue": "No module named 'tensorflow.examples.tutorials'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)", "\u001b[0;32m<ipython-input-3-106a86e1593a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples.tutorials'"]}]}, {"metadata": {"colab": {}, "colab_type": "code", "id": "mZ-1elJrI4lg"}, "cell_type": "code", "source": "PLOT_DIR = './out/plots'", "execution_count": 4, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "b9FWvSWZI4ln"}, "cell_type": "code", "source": "def get_grid_dim(x):\n    \"\"\"\n    Transforms x into product of two integers\n    :param x: int\n    :return: two ints\n    \"\"\"\n    factors = prime_powers(x)\n    if len(factors) % 2 == 0:\n        i = int(len(factors) / 2)\n        return factors[i], factors[i - 1]\n\n    i = len(factors) // 2\n    return factors[i], factors[i]\n\n\ndef prime_powers(n):\n    \"\"\"\n    Compute the factors of a positive integer\n    Algorithm from https://rosettacode.org/wiki/Factors_of_an_integer#Python\n    :param n: int\n    :return: set\n    \"\"\"\n    factors = set()\n    for x in range(1, int(math.sqrt(n)) + 1):\n        if n % x == 0:\n            factors.add(int(x))\n            factors.add(int(n // x))\n    return sorted(factors)\n\n\ndef empty_dir(path):\n    \"\"\"\n    Delete all files and folders in a directory\n    :param path: string, path to directory\n    :return: nothing\n    \"\"\"\n    for the_file in os.listdir(path):\n        file_path = os.path.join(path, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print ('Warning: {}'.format(e))\n\n\ndef create_dir(path):\n    \"\"\"\n    Creates a directory\n    :param path: string\n    :return: nothing\n    \"\"\"\n    try:\n        os.makedirs(path)\n    except OSError as exc:\n        if exc.errno != errno.EEXIST:\n            raise\n\n\ndef prepare_dir(path, empty=False):\n    \"\"\"\n    Creates a directory if it soes not exist\n    :param path: string, path to desired directory\n    :param empty: boolean, delete all directory content if it exists\n    :return: nothing\n    \"\"\"\n    if not os.path.exists(path):\n        create_dir(path)\n\n    if empty:\n        empty_dir(path)", "execution_count": 5, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "ZzN_52EVI4lq"}, "cell_type": "code", "source": "def plot_conv_weights(weights, name, channels_all=True):\n    \"\"\"\n    Plots convolutional filters\n    :param weights: numpy array of rank 4\n    :param name: string, name of convolutional layer\n    :param channels_all: boolean, optional\n    :return: nothing, plots are saved on the disk\n    \"\"\"\n    # make path to output folder\n    plot_dir = os.path.join(PLOT_DIR, 'conv_weights')\n    plot_dir = os.path.join(plot_dir, name)\n\n    # create directory if does not exist, otherwise empty it\n    # utils.prepare_dir(plot_dir, empty=True)\n    prepare_dir(plot_dir, empty=True)\n\n    w_min = np.min(weights)\n    w_max = np.max(weights)\n\n    channels = [0]\n    # make a list of channels if all are plotted\n    if channels_all:\n        channels = range(weights.shape[2])\n\n    # get number of convolutional filters\n    num_filters = weights.shape[3]\n\n    # get number of grid rows and columns\n    grid_r, grid_c = get_grid_dim(num_filters)\n\n    # create figure and axes\n    fig, axes = plt.subplots(min([grid_r, grid_c]),\n                             max([grid_r, grid_c]))\n\n    # iterate channels\n    for channel in channels:\n        # iterate filters inside every channel\n        for l, ax in enumerate(axes.flat):\n            # get a single filter\n            img = weights[:, :, channel, l]\n            # put it on the grid\n            ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n            # remove any labels from the axes\n            ax.set_xticks([])\n            ax.set_yticks([])\n        # save figure\n        plt.savefig(os.path.join(plot_dir, '{}-{}.png'.format(name, channel)), bbox_inches='tight')\n\n\ndef plot_conv_output(conv_img, name):\n    \"\"\"\n    Makes plots of results of performing convolution\n    :param conv_img: numpy array of rank 4\n    :param name: string, name of convolutional layer\n    :return: nothing, plots are saved on the disk\n    \"\"\"\n    # make path to output folder\n    plot_dir = os.path.join(PLOT_DIR, 'conv_output')\n    plot_dir = os.path.join(plot_dir, name)\n\n    # create directory if does not exist, otherwise empty it\n    prepare_dir(plot_dir, empty=True)\n\n    w_min = np.min(conv_img)\n    w_max = np.max(conv_img)\nc\n    # get number of convolutional filters\n    num_filters = conv_img.shape[3]\n\n    # get number of grid rows and columns\n    grid_r, grid_c = get_grid_dim(num_filters)\n\n    # create figure and axes\n    fig, axes = plt.subplots(min([grid_r, grid_c]),\n                             max([grid_r, grid_c]))\n\n    # iterate filters\n    for l, ax in enumerate(axes.flat):\n        # get a single image\n        img = conv_img[0, :, :,  l]\n        # put it on the grid\n        ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='bicubic', cmap='Greys')\n        # remove any labels from the axes\n        ax.set_xticks([])\n        ax.set_yticks([])\n    # save figure\n    plt.savefig(os.path.join(plot_dir, '{}.png'.format(name)), bbox_inches='tight')", "execution_count": 6, "outputs": [{"output_type": "error", "ename": "IndentationError", "evalue": "unexpected indent (<ipython-input-6-076962179716>, line 68)", "traceback": ["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-076962179716>\"\u001b[0;36m, line \u001b[0;32m68\u001b[0m\n\u001b[0;31m    num_filters = conv_img.shape[3]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 748}, "colab_type": "code", "id": "31V14lEAI4lw", "outputId": "63be20b8-32de-4af2-8b86-ebecf321a046"}, "cell_type": "code", "source": "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)\n\n# Parameters\nlearning_rate = 0.001\ntraining_iters = 10000\nbatch_size = 128\ndisplay_step = 10\n\n# Network Parameters\nn_input = 784  # MNIST data input (img shape: 28*28)\nn_classes = 10  # MNIST total classes (0-9 digits)\ndropout = 0.75  # Dropout, probability to keep units\n\n# tf Graph input\nx = tf.placeholder(tf.float32, [None, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32)  # dropout (keep probability)\n\n\ndef conv2d(x_, filter_size, filter_num, stride=1):\n    \"\"\"\n    Wrapper of a convolutional layer\n    :param x_: tensor, input to convolutional layer\n    :param filter_size: int, size of a convolutional kernel\n    :param filter_num: int, number of convolutional kernels\n    :param stride: int, optional, stride\n    :return: tensor\n    \"\"\"\n    # get number of channels in input\n    channels = x_.get_shape()[3].value\n\n    # create weights tensor\n    weights = tf.Variable(tf.random_normal([filter_size, filter_size, channels, filter_num]))\n\n    # add weights tensor to collection\n    tf.add_to_collection('conv_weights', weights)\n\n    # create bias tensor\n    bias = tf.Variable(tf.random_normal([filter_num]))\n\n    # apply weights and biases\n    preactivations = tf.nn.conv2d(x_, weights, strides=[1, stride, stride, 1], padding='SAME')\n    preactivations = tf.nn.bias_add(preactivations, bias)\n\n    # apply activation function, this is layer output\n    activations = tf.nn.relu(preactivations)\n\n    # add output to collection\n    tf.add_to_collection('conv_output', activations)\n\n    return activations\n\n\ndef fc(x_, nodes, keep_prob_=1, act=tf.nn.relu):\n    \"\"\"\n    Wrapper for fully-connected layer\n    :param x_: tensor, input to fully-connected alyer\n    :param nodes: int, number of nodes in layer\n    :param keep_prob_: float, optional, keep probability for dropout operation\n    :param act: tf.nn method, optional, activation function\n    :return: tensor\n    \"\"\"\n    shape = x_.get_shape()\n\n    # if rank of input tensor is greater than 2\n    # we need to reshape it\n    if shape.ndims > 2:\n        n = 1\n        for s in shape[1:]:\n            n *= s.value\n        x_ = tf.reshape(x_, tf.stack([-1, n]))\n        x_.set_shape([None, n])\n\n    # get number of column in input tensor\n    n = x_.get_shape()[1].value\n\n    # create weights\n    weights = tf.Variable(tf.random_normal([n, nodes]))\n\n    # create biases\n    bias = tf.Variable(tf.random_normal([nodes]))\n\n    # apply weights and bias\n    preactivate = tf.add(tf.matmul(x_, weights), bias)\n    out = preactivate\n\n    # apply activation function if not None\n    if act is not None:\n        out = act(preactivate)\n\n    # apply dropout\n    out = tf.nn.dropout(out, keep_prob_)\n\n    return out\n\n\ndef maxpool(x_, size, stride):\n    \"\"\"\n    Wrapper for max-pooling layer\n    :param x_: tensor, input to max-pooling layer\n    :param size: int\n    :param stride: int\n    :return: tensor\n    \"\"\"\n    return tf.nn.max_pool(x_,\n                          ksize=[1, size, size, 1],\n                          strides=[1, stride, stride, 1],\n                          padding='SAME')\n\n# Reshape inputs\nx_reshaped = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n# First convolutional layer\npredictions = conv2d(x_reshaped, filter_size=5, filter_num=32)\n\n# First max-pooling layer\npredictions = maxpool(predictions, 2, 2)\n\n# Second convolutional layer\npredictions = conv2d(predictions, filter_size=5, filter_num=64)\n\n# Second max-pooling layer\npredictions = maxpool(predictions, 2, 2)\n\n# First fully-connected layer\npredictions = fc(predictions, 1024, keep_prob)\n\n# Output layer, no activation function\n# This layer returns logits\npredictions = fc(predictions, n_classes, keep_prob, act=None)\n\n# Define loss operation\n#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predictions, y))\nval = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = predictions) \ncost = tf.reduce_mean(val)\n\n\n# Define optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Define accuracy operation\ncorrect_predictions = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n\n# Initializing the variables\ninit = tf.initialize_all_variables()", "execution_count": 7, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'input_data' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-7-c6f22fff9fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'input_data' is not defined"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 234}, "colab_type": "code", "id": "U5-X2WAVI4lz", "outputId": "3dd74379-d51f-4b8f-82fd-d559a05cf28b"}, "cell_type": "code", "source": "with tf.Session() as sess:\n    sess.run(init)\n    step = 1\n    # Keep training until reach max iterations\n    while step * batch_size < training_iters:\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n                                   keep_prob: dropout})\n        if step % display_step == 0:\n            # Calculate batch loss and accuracy\n            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                          y: batch_y,\n                                                          keep_prob: 1.})\n            print(\"\\rIter \" + str(step*batch_size) + \", Minibatch Loss= \" +\n              \"{:.6f}\".format(loss) + \", Training Accuracy= \" +\n              \"{:.5f}\".format(acc), end='')\n        step += 1\n    print(\"\\rOptimization Finished!\")\n    # Calculate accuracy for 256 mnist test images\n    print(\"Testing Accuracy:\",\n    sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n                                y: mnist.test.labels[:256],\n                                keep_prob: 1.}))\n    # no need for feed dictionary here\n    conv_weights = sess.run([tf.get_collection('conv_weights')])\n    conv_out = sess.run([tf.get_collection('conv_output')], feed_dict={x: mnist.test.images[:1]})\n    print(\"conv_weights & conv_out done!\")    ", "execution_count": 8, "outputs": [{"output_type": "error", "ename": "AttributeError", "evalue": "module 'tensorflow' has no attribute 'Session'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-8-a5bfc827b10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Keep training until reach max iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtraining_iters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 515}, "colab_type": "code", "id": "lim6jPpHI4l0", "outputId": "e9053ae4-b56e-47df-b5b5-1a9d8f5868e0"}, "cell_type": "code", "source": "  # get weights of all convolutional layers\n  # no need for feed dictionary here \n  for i, c in enumerate(conv_weights[0]):\n        plot_conv_weights(c, 'conv{}'.format(i))", "execution_count": 9, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'conv_weights' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-9-704d1f8bc759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get weights of all convolutional layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# no need for feed dictionary here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mplot_conv_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'conv_weights' is not defined"]}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 515}, "colab_type": "code", "id": "PPBut-HsS6KU", "outputId": "5e2ab874-5242-4dd3-94f6-ccec4c1b6d3d"}, "cell_type": "code", "source": " # get output of all convolutional layers\n # here we need to provide an input imag   \n   for i, c in enumerate(conv_out[0]): \n        plot_conv_output(c, 'conv{}'.format(i))\n#        ", "execution_count": 10, "outputs": [{"output_type": "error", "ename": "IndentationError", "evalue": "unexpected indent (<ipython-input-10-69402a38a25d>, line 3)", "traceback": ["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-69402a38a25d>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for i, c in enumerate(conv_out[0]):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]}, {"metadata": {}, "cell_type": "code", "source": "#", "execution_count": 11, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "colab_type": "code", "id": "239iF48xe7xw", "outputId": "9a2ad7b6-e5bb-4b4d-b190-b60c4a4499e6"}, "cell_type": "code", "source": "#!ls -lR", "execution_count": 12, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "hlnB98l0I4l3"}, "cell_type": "code", "source": "  # print(conv_weights[0])", "execution_count": 13, "outputs": []}, {"metadata": {"colab": {}, "colab_type": "code", "id": "52ZV9c5AI4l6"}, "cell_type": "code", "source": "#    print(conv_out[0])", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"colab": {"collapsed_sections": [], "name": "MNIST CNN filter visualization copy 1.ipynb", "provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}