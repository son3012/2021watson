{"cells": [{"metadata": {"scrolled": true}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_898a030403f7485eb967ba42b0aa73e9 = 'https://s3-api.us-geo.objectstorage.softlayer.net'\nelse:\n    endpoint_898a030403f7485eb967ba42b0aa73e9 = 'https://s3-api.us-geo.objectstorage.service.networklayer.com'\n\nclient_898a030403f7485eb967ba42b0aa73e9 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='pBEYHEt6kq6wZUv4qf0CrCa-RwJvFHgMgC81kXLzcrIe',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url=endpoint_898a030403f7485eb967ba42b0aa73e9)\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_1 = client_898a030403f7485eb967ba42b0aa73e9.get_object(Bucket='rklb-donotdelete-pr-rdv6sie7airyfr', Key='Iris.csv (2).ipynb')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_1, \"__iter__\"): streaming_body_1.__iter__ = types.MethodType( __iter__, streaming_body_1 ) \n", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow.compat.v1 as tf \ntf.compat.v1.disable_eager_execution()", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 4594386863221931056\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 6829857122635831826\nphysical_device_desc: \"device: XLA_CPU device\"\n]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#\ud488\uc885 column\uc744 one-hot-encode\niris_data_one_hot_encoded = pd.get_dummies(df_data_1)\niris_data_one_hot_encoded.head(5)", "execution_count": 5, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'df_data_1' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-5-1cb58fd1d54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\ud488\uc885 column\uc744 one-hot-encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miris_data_one_hot_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0miris_data_one_hot_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'df_data_1' is not defined"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Visualize the Data"}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\n\nnames = {'Iris-setosa','Iris-versicolor','Iris-virginica'}\nfeature_names = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']\nlabels=df_data_1.iloc[:,5]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize the data sets\nplt.figure(figsize=(16, 6))\nplt.subplot(1, 2, 1)\nfor target, target_name in enumerate(names):\n    X_plot = df_data_1[labels== target_name]\n    plt.plot(X_plot.iloc[:, 1], X_plot.iloc[:, 2], linestyle='none', marker='o', label=target_name)\nplt.xlabel(feature_names[0])\nplt.ylabel(feature_names[1])\nplt.axis('equal')\nplt.legend();\n\n\nplt.subplot(1, 2, 2)\nfor target, target_name in enumerate(names):\n    X_plot = df_data_1[labels== target_name]\n    plt.plot(X_plot.iloc[:, 3], X_plot.iloc[:, 4], linestyle='none', marker='o', label=target_name)\nplt.xlabel(feature_names[2])\nplt.ylabel(feature_names[3])\nplt.axis('equal')\nplt.legend();", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#\uc804\uccb4 \ub370\uc774\ud130\ub97c 80%\uc740 \ud2b8\ub808\uc774\ub2dd 20% \ud14c\uc2a4\ud2b8\ub85c \ucabc\uac2c\niris_train_data = iris_data_one_hot_encoded.sample(frac=0.8, random_state=200)\niris_test_data = iris_data_one_hot_encoded.drop(iris_train_data.index)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#input\uc740 \uaf43\uc78e\uc758 \ub108\ube44\uc640\uae38\uc774, \uaf43\ubc1b\uce68\uc758 \ub108\ube44\uc640\uae38\uc774\n#output\uc740 \uc138\uac1c\uc911 \ud558\ub098\ub85c\niris_train_input_data = iris_train_data.filter(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])\niris_train_label_data = iris_train_data.filter(['Species_Iris-setosa', 'Species_Iris-versicolor', 'Species_Iris-virginica'])\niris_test_input_data = iris_test_data.filter(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])\niris_test_label_data = iris_test_data.filter(['Species_Iris-setosa', 'Species_Iris-versicolor', 'Species_Iris-virginica'])\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#x\ub294 input\uac12\uc744 \uc704\ud55c placeholder\n#w\ub294 \uac00\uc911\uce58\n#b\ub294 \ud3b8\ucc28\n#y\ub294 \ud2b8\ub808\uc774\ub2dd\ud574\uc11c \ub098\uc628 \uacb0\uacfc(\uac00\uc124)\n#y_\ub294 \uc9c4\uc9dc \uacb0\uacfc\uac12\nx = tf.placeholder(tf.float32,[None, 4])\nW = tf.Variable(tf.zeros([4, 3]))\nb = tf.Variable(tf.zeros([3]))\ny = tf.nn.softmax(tf.matmul(x, W) + b)\ny_ = tf.placeholder(tf.float32, [None, 3])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#cross_entropy\ub97c cost\ud568\uc218\ub85c\ncross_entropy  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=tf.matmul(x,W)+b))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#cost\ub97c \ucd5c\uc18c\ud654\ntrain_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "sess = tf.InteractiveSession()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "#30,000\ubc88 \ud559\uc2b5\n#tf.global_variables_initializer().run()\nepoch_history = []\nloss_history = []\n\nsess.run(tf.global_variables_initializer())\nfor _ in range(30000):\n    #Usually send batches to the training step. But since the dataset is small sending all\n    l,a=sess.run([cross_entropy,train_step], feed_dict={x: iris_train_input_data, y_: iris_train_label_data})\n    epoch_history.append(_)\n    loss_history.append(l)\n\nprint(\"trained\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Crossentropy vs. epoch"}, {"metadata": {}, "cell_type": "code", "source": "#Draw Cross Entropy Graph\nplt.xlabel('Epochs')\nplt.ylabel('crossentropy')\n\n\n# Show the cross_entropy\nplt.plot(epoch_history, loss_history)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n#\uc815\ud655\ub3c4\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nprint('Accuracy : ', sess.run(accuracy, feed_dict={x: iris_test_input_data, y_: iris_test_label_data}))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#\ucd94\ub860\npredict_x = np.array([[6.9,3.1,5.4,2.1]])\nprediction=tf.argmax(y,1)\nprint('\uc608\uce21\uac12:', sess.run(prediction, feed_dict={x: predict_x}))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predict_x = np.array([[5.1,3.3,1.7,0.5]])\nprediction=tf.argmax(y,1)\nprint('\uc608\uce21\uac12:', sess.run(prediction, feed_dict={x: predict_x}))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## ROC Curve"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "# quality of the neural net using ROC curve and AUC\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n#test\uc778\ud48b\uc758 \uc608\uce21\uac12\ntest_prob=sess.run(tf.nn.softmax(logits=tf.matmul(x,W)+b), feed_dict={x: iris_test_input_data})\n#print(test_prob.ravel())\n\n#test\uc778\ud48b\uc758 label\ntest_label=sess.run(tf.argmax(y_,1), feed_dict={y_: iris_test_label_data})\n#print(test_label)\n\n#test\uc778\ud48b\uc758 binarized\nbi_test_label = label_binarize(test_label, classes=[0, 1, 2])\n#print(bi_test_label)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# send the actual dependent variable classifications for param 1, \n# and the confidences of the true classification for param 2.\n#roc_curve\ub294 multiclass&multi_Indicater\uc758 \uc785\ub825\uc774 \ub418\uc9c0 \uc54a\uc73c\ubbc0\ub85c ravel()\uc744 \ud1b5\ud574 1\ucc28\uc6d0\ubc30\uc5f4\ub85c \ud3bc\uce68\nfpr,tpr,thr= roc_curve(bi_test_label.ravel(), test_prob.ravel())\nAUC = auc(fpr,tpr)\nplt.plot(fpr, tpr,label='%s(area = %0.2f)' %('Model',AUC))\n\nplt.legend(loc=\"lower right\")\n#plt.xlabel('\uc704\uc591\uc131\ub960(Fall-Out)')\n#plt.ylabel('\uc7ac\ud604\ub960(Recall)')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Confusion Matrix"}, {"metadata": {}, "cell_type": "code", "source": "#confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\nprint('label : ',test_label)\ntest_pred=sess.run(tf.argmax(y,1), feed_dict={x: iris_test_input_data})\nprint('predict: ',test_pred)\n\nconfM=confusion_matrix(test_label,test_pred)\nprint(confM)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}