{"cells": [{"metadata": {"id": "yTDwLZkW7zlk"}, "cell_type": "code", "source": "import numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n%matplotlib inline", "execution_count": 1, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "1sHhzKsE7zlm", "outputId": "90e106eb-7f80-4755-e6b8-6c23009740ce"}, "cell_type": "code", "source": "from tensorflow.keras.datasets import fashion_mnist\n(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()", "execution_count": 2, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "E3fVSoc87zln", "outputId": "da4c2986-b4aa-40c3-eb81-0afa7400ae1e"}, "cell_type": "code", "source": "print('Training data shape : ', train_X.shape, train_Y.shape)\n\nprint('Testing data shape : ', test_X.shape, test_Y.shape)", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Training data shape :  (60000, 28, 28) (60000,)\nTesting data shape :  (10000, 28, 28) (10000,)\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "0Yjfo7hs7zlo", "outputId": "a66c1142-d103-4395-cb95-5384115bc068"}, "cell_type": "code", "source": "# Find the unique numbers from the train labels\nclasses = np.unique(train_Y)\nnClasses = len(classes)\nprint('Total number of outputs : ', nClasses)\nprint('Output classes : ', classes)", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Total number of outputs :  10\nOutput classes :  [0 1 2 3 4 5 6 7 8 9]\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 208}, "id": "fL_PQ6X27zlo", "outputId": "b9aafcb7-6e60-4aa1-9723-2625d3746146"}, "cell_type": "code", "source": "plt.figure(figsize=[5,5])\n\n# Display the first image in training data\nplt.subplot(121)\nplt.imshow(train_X[0,:,:], cmap='gray')\nplt.title(\"Ground Truth : {}\".format(train_Y[0]))\n\n# Display the first image in testing data\nplt.subplot(122)\nplt.imshow(test_X[0,:,:], cmap='gray')\nplt.title(\"Ground Truth : {}\".format(test_Y[0]))", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "Text(0.5, 1.0, 'Ground Truth : 9')"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<Figure size 360x360 with 2 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "p4GoiSCp7zlo", "outputId": "f68f1b97-f39a-4bfe-d0a4-1ca9f4ef15f9"}, "cell_type": "code", "source": "train_X = train_X.reshape(-1, 28,28, 1)\ntest_X = test_X.reshape(-1, 28,28, 1)\ntrain_X.shape, test_X.shape", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "((60000, 28, 28, 1), (10000, 28, 28, 1))"}, "metadata": {}}]}, {"metadata": {"id": "m4mRc2Bw7zlp"}, "cell_type": "code", "source": "train_X = train_X.astype('float32')\ntest_X = test_X.astype('float32')\ntrain_X = train_X / 255.\ntest_X = test_X / 255.", "execution_count": 7, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "aikn9ldV7zlp", "outputId": "a7f61f47-e18e-4e5a-f28f-11565980851b"}, "cell_type": "code", "source": "# Change the labels from categorical to one-hot encoding\ntrain_Y_one_hot = to_categorical(train_Y)\ntest_Y_one_hot = to_categorical(test_Y)\n\n# Display the change for category label using one-hot encoding\nprint('Original label:', train_Y[0])\nprint('After conversion to one-hot:', train_Y_one_hot[0])", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Original label: 9\nAfter conversion to one-hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n", "name": "stdout"}]}, {"metadata": {"id": "raoirUhl7zlq"}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\ntrain_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)", "execution_count": 9, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Ww7EW2oI7zlq", "outputId": "2fbc61d6-43c8-4c09-fe83-4fb800c059f7"}, "cell_type": "code", "source": "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "((48000, 28, 28, 1), (12000, 28, 28, 1), (48000, 10), (12000, 10))"}, "metadata": {}}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 71}, "id": "ArJMkgJK7zlr", "outputId": "96059c1d-eed3-47ba-804c-ba3d1bc9ea54"}, "cell_type": "code", "source": "\"\"\"\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\"\"\"", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "'\\nmodel = keras.Sequential(\\n    [\\n        keras.Input(shape=input_shape),\\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\\n        layers.MaxPooling2D(pool_size=(2, 2)),\\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\\n        layers.MaxPooling2D(pool_size=(2, 2)),\\n        layers.Flatten(),\\n        layers.Dropout(0.5),\\n        layers.Dense(num_classes, activation=\"softmax\"),\\n    ]\\n)\\n'"}, "metadata": {}}]}, {"metadata": {"id": "NuZ2MGRy7zlr"}, "cell_type": "code", "source": "from tensorflow.keras.models import Sequential #,Input, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D \nfrom tensorflow.keras.layers import BatchNormalization\n#from tensorflow.keras.layers.advanced_activations import LeakyReLU", "execution_count": 12, "outputs": []}, {"metadata": {"id": "vmnDCYkz7zlr"}, "cell_type": "code", "source": "batch_size = 64 #=64\nepochs = 13\nnum_classes = 10", "execution_count": 13, "outputs": []}, {"metadata": {"id": "DgcvXL7K7zls"}, "cell_type": "code", "source": "fashion_model = Sequential()\nfashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\n#fashion_model.add(Conv2D(32, kernel_size=(3, 3),input_shape=(28,28,1),padding='same'))\n#fashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model.add(MaxPooling2D((2, 2),padding='same'))\nfashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n#fashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n#fashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model.add(Flatten())\nfashion_model.add(Dense(128, activation='linear'))\n#fashion_model.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model.add(Dense(num_classes, activation='softmax'))", "execution_count": 14, "outputs": []}, {"metadata": {"id": "gl6vCa6E7zls"}, "cell_type": "code", "source": "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])", "execution_count": 15, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "bJ5i3HfI7zls", "outputId": "0221b55c-9601-46a4-b268-9cef3e5a9870"}, "cell_type": "code", "source": "fashion_model.summary()", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 28, 28, 32)        320       \n_________________________________________________________________\nactivation (Activation)      (None, 28, 28, 32)        0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n_________________________________________________________________\nactivation_1 (Activation)    (None, 14, 14, 64)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 7, 7, 128)         0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               262272    \n_________________________________________________________________\nactivation_3 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 356,234\nTrainable params: 356,234\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4oDWtO007zlt", "outputId": "87585d46-0f48-4011-aebd-32a41a2abefa"}, "cell_type": "code", "source": "fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Train on 48000 samples, validate on 12000 samples\nEpoch 1/13\n47936/48000 [============================>.] - ETA: 5s - loss: 0.4883 - accuracy: 0.8226 ", "name": "stdout"}]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "jJYDMsOL7zlt", "outputId": "a5692546-566b-4dba-c599-3ce83d39bfdd"}, "cell_type": "code", "source": "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose=0)\nprint('Test loss:', test_eval[0])\nprint('Test accuracy:', test_eval[1])", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 545}, "id": "1Ljj-ZfX7zlt", "outputId": "d6bda41d-dcfa-4032-bec6-1dd0f09b98ce"}, "cell_type": "code", "source": "accuracy = fashion_train.history['accuracy']\nval_accuracy = fashion_train.history['val_accuracy']\nloss = fashion_train.history['loss']\nval_loss = fashion_train.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "hj1uvOYP7zlu", "outputId": "991a21c4-b88e-4d48-b2ab-456ede7556b1"}, "cell_type": "code", "source": "fashion_model.save(\"fashion_model_Nodropout.py\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "mWuPpD-57zlu"}, "cell_type": "code", "source": "batch_size = 64\nepochs = 13\nnum_classes = 10", "execution_count": null, "outputs": []}, {"metadata": {"id": "wosuKdbG7zlu"}, "cell_type": "code", "source": "fashion_model2 = Sequential()\nfashion_model2.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\n#fashion_model2.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model2.add(MaxPooling2D((2, 2),padding='same'))\nfashion_model2.add(Dropout(0.25))\nfashion_model2.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n#fashion_model2.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model2.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model2.add(Dropout(0.25))\nfashion_model2.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n#fashion_model2.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model2.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nfashion_model2.add(Dropout(0.4))\nfashion_model2.add(Flatten())\nfashion_model2.add(Dense(128, activation='linear'))\n#fashion_model2.add(LeakyReLU(alpha=0.1))\nfashion_model.add(Activation('relu'))\nfashion_model2.add(Dropout(0.3))\nfashion_model2.add(Dense(num_classes, activation='softmax'))", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "2kQ6TBQf7zlv", "outputId": "ccecadce-8aac-44e4-eb41-1377ed316ac2"}, "cell_type": "code", "source": "fashion_model2.summary()", "execution_count": null, "outputs": []}, {"metadata": {"id": "Z0I53-Ar7zlv"}, "cell_type": "code", "source": "fashion_model2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qISWI2S_7zlv", "outputId": "bc928f3d-c1a9-4959-840f-fc70643b1e85"}, "cell_type": "code", "source": "fashion_train_dropout = fashion_model2.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KQBmrEdX7zlv", "outputId": "30dbd800-9241-4742-de01-74f30bd0c2d8"}, "cell_type": "code", "source": "fashion_model2.save(\"fashion_model_dropout.py\")", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fzQiwTRZ7zlw", "outputId": "2cf15a54-89ee-461c-cedc-1475d89cfa0a"}, "cell_type": "code", "source": "test_eval = fashion_model2.evaluate(test_X, test_Y_one_hot, verbose=1)\nprint('Test loss:', test_eval[0])\nprint('Test accuracy:', test_eval[1])", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 545}, "id": "9fVi97Yp7zlw", "outputId": "48323f05-78ba-4179-df34-79176c992e59"}, "cell_type": "code", "source": "accuracy = fashion_train_dropout.history['accuracy']\nval_accuracy = fashion_train_dropout.history['val_accuracy']\nloss = fashion_train_dropout.history['loss']\nval_loss = fashion_train_dropout.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "BWtN6Gud7zlw", "outputId": "c0c8345f-b25a-4859-a8b8-01606831a747"}, "cell_type": "code", "source": "predicted_classes = fashion_model2.predict(test_X)\npredicted_classes = np.argmax(np.round(predicted_classes),axis=1)\npredicted_classes.shape, test_Y.shape", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 314}, "id": "aq7MogwO7zlw", "outputId": "ef371397-85f2-4ab0-fdad-f59b7667a4ca"}, "cell_type": "code", "source": "correct = np.where(predicted_classes==test_Y)[0]\nprint (\"Found %d correct labels\" % len(correct))\nfor i, correct in enumerate(correct[:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(test_X[correct].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], test_Y[correct]))\n    plt.tight_layout()", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 314}, "id": "59fBmiqV7zlx", "outputId": "1fd640d3-7848-465a-b2c9-318d35c7335b"}, "cell_type": "code", "source": "incorrect = np.where(predicted_classes!=test_Y)[0]\nprint(\"Found %d incorrect labels\" % len(incorrect))\nfor i, incorrect in enumerate(incorrect[:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(test_X[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], test_Y[incorrect]))\n    plt.tight_layout()", "execution_count": null, "outputs": []}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rtJ6pcKp7zlx", "outputId": "d1591290-947d-4b3b-c53b-f780bec6746c"}, "cell_type": "code", "source": "from sklearn.metrics import classification_report\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(test_Y, predicted_classes, target_names=target_names))", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "colab": {"name": "Dropout test using fashion mnist dataset-full-2.ipynb", "provenance": [], "collapsed_sections": []}}, "nbformat": 4, "nbformat_minor": 1}